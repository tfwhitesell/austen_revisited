{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import helper_functions as h\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import nltk\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, accuracy_score, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import helper_functions as h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_2000 = pd.read_csv('../data/token_2000.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same text segments, how will more pre-processing affect the model outcomes? So far, tf-idf has under performed count vectorizer which is unexpected. Doing stopword removal after tokenization so the portion of the text in each chunk remains stable. I've added honorifics (Mr, Mrs, Miss) to the stopword list since those words are so common in Austen's writing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "token_2000['no_stops'] = token_2000['token_text'].apply(h.remove_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text#</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>words</th>\n",
       "      <th>text_length</th>\n",
       "      <th>is_Austen</th>\n",
       "      <th>is_Austen_bool</th>\n",
       "      <th>token_text</th>\n",
       "      <th>token_num</th>\n",
       "      <th>token_char_count</th>\n",
       "      <th>token_sent_count</th>\n",
       "      <th>token_word_count</th>\n",
       "      <th>no_stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52705351</td>\n",
       "      <td>The Meek Shall Inherit</td>\n",
       "      <td>AvonleaBrigadoon</td>\n",
       "      <td>67407</td>\n",
       "      <td>long</td>\n",
       "      <td>Not Austen</td>\n",
       "      <td>0</td>\n",
       "      <td>21 July 1809 I am sixteen today: an age at whi...</td>\n",
       "      <td>1</td>\n",
       "      <td>1994</td>\n",
       "      <td>29</td>\n",
       "      <td>381</td>\n",
       "      <td>21 July 1809 sixteen today : age often talk co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>52705351</td>\n",
       "      <td>The Meek Shall Inherit</td>\n",
       "      <td>AvonleaBrigadoon</td>\n",
       "      <td>67407</td>\n",
       "      <td>long</td>\n",
       "      <td>Not Austen</td>\n",
       "      <td>0</td>\n",
       "      <td>24 July I have conquered the first phrase with...</td>\n",
       "      <td>2</td>\n",
       "      <td>1989</td>\n",
       "      <td>23</td>\n",
       "      <td>378</td>\n",
       "      <td>24 July conquered first phrase hands , includi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52705351</td>\n",
       "      <td>The Meek Shall Inherit</td>\n",
       "      <td>AvonleaBrigadoon</td>\n",
       "      <td>67407</td>\n",
       "      <td>long</td>\n",
       "      <td>Not Austen</td>\n",
       "      <td>0</td>\n",
       "      <td>Jane and Lizzy tried speaking to Papa, saying ...</td>\n",
       "      <td>3</td>\n",
       "      <td>1966</td>\n",
       "      <td>23</td>\n",
       "      <td>384</td>\n",
       "      <td>Jane Lizzy tried speaking Papa , saying two fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52705351</td>\n",
       "      <td>The Meek Shall Inherit</td>\n",
       "      <td>AvonleaBrigadoon</td>\n",
       "      <td>67407</td>\n",
       "      <td>long</td>\n",
       "      <td>Not Austen</td>\n",
       "      <td>0</td>\n",
       "      <td>I was so embarrassed, that I was not able to a...</td>\n",
       "      <td>4</td>\n",
       "      <td>1929</td>\n",
       "      <td>23</td>\n",
       "      <td>347</td>\n",
       "      <td>embarrassed , able attend introduction danced ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52705351</td>\n",
       "      <td>The Meek Shall Inherit</td>\n",
       "      <td>AvonleaBrigadoon</td>\n",
       "      <td>67407</td>\n",
       "      <td>long</td>\n",
       "      <td>Not Austen</td>\n",
       "      <td>0</td>\n",
       "      <td>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 28 December, 18...</td>\n",
       "      <td>5</td>\n",
       "      <td>1992</td>\n",
       "      <td>25</td>\n",
       "      <td>364</td>\n",
       "      <td>~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 28 December , 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text#                   title            author  words text_length  \\\n",
       "0  52705351  The Meek Shall Inherit  AvonleaBrigadoon  67407        long   \n",
       "1  52705351  The Meek Shall Inherit  AvonleaBrigadoon  67407        long   \n",
       "2  52705351  The Meek Shall Inherit  AvonleaBrigadoon  67407        long   \n",
       "3  52705351  The Meek Shall Inherit  AvonleaBrigadoon  67407        long   \n",
       "4  52705351  The Meek Shall Inherit  AvonleaBrigadoon  67407        long   \n",
       "\n",
       "    is_Austen  is_Austen_bool  \\\n",
       "0  Not Austen               0   \n",
       "1  Not Austen               0   \n",
       "2  Not Austen               0   \n",
       "3  Not Austen               0   \n",
       "4  Not Austen               0   \n",
       "\n",
       "                                          token_text  token_num  \\\n",
       "0  21 July 1809 I am sixteen today: an age at whi...          1   \n",
       "1  24 July I have conquered the first phrase with...          2   \n",
       "2  Jane and Lizzy tried speaking to Papa, saying ...          3   \n",
       "3  I was so embarrassed, that I was not able to a...          4   \n",
       "4  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 28 December, 18...          5   \n",
       "\n",
       "   token_char_count  token_sent_count  token_word_count  \\\n",
       "0              1994                29               381   \n",
       "1              1989                23               378   \n",
       "2              1966                23               384   \n",
       "3              1929                23               347   \n",
       "4              1992                25               364   \n",
       "\n",
       "                                            no_stops  \n",
       "0  21 July 1809 sixteen today : age often talk co...  \n",
       "1  24 July conquered first phrase hands , includi...  \n",
       "2  Jane Lizzy tried speaking Papa , saying two fu...  \n",
       "3  embarrassed , able attend introduction danced ...  \n",
       "4  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ 28 December , 1...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_2000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_2000.to_csv('../data/token_2000_no_stop.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for full pre-processing\n",
    "def preprocess_text(df, col_name, new_col_name):\n",
    "    stop_words = h.get_stopwords()\n",
    "    lem = WordNetLemmatizer()\n",
    "\n",
    "    def process(text):\n",
    "        text = text.lower()\n",
    "        words = word_tokenize(text)\n",
    "        filtered_words = [lem.lemmatize(word) for word in words if word not in stop_words and word not in string.punctuation]\n",
    "        \n",
    "        return ' '.join(filtered_words)\n",
    "    \n",
    "    df[new_col_name] = df[col_name].apply(process)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed = preprocess_text(token_2000, 'token_text', 'processed_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed.to_csv('../data/processed.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning this into a function at last\n",
    "\n",
    "def mnb_model(df, text_col, class_col, vect):\n",
    "    # list to iterate over\n",
    "    ids = df['text#'].unique().tolist()\n",
    "\n",
    "    logo_list = []\n",
    "    item_count = 0\n",
    "\n",
    "    for id in ids:\n",
    "        train_ids = list(filter(lambda x: x != id, ids))\n",
    "        test_ids = [id]\n",
    "\n",
    "        # subset dataframe for test id\n",
    "        id_tokens = df[df['text#'] == id].copy()\n",
    "\n",
    "        # train-test-split\n",
    "        X_train = df[df['text#'].isin(train_ids)][text_col]\n",
    "        X_test = df[df['text#'].isin(test_ids)][text_col]\n",
    "        y_train = df[df['text#'].isin(train_ids)][class_col]\n",
    "        y_test = df[df['text#'].isin(test_ids)][class_col]\n",
    "\n",
    "        vect = vect\n",
    "\n",
    "        X_train_vec = vect.fit_transform(X_train)\n",
    "        X_test_vec = vect.transform(X_test)\n",
    "\n",
    "        nb = MultinomialNB().fit(X_train_vec, y_train)\n",
    "\n",
    "        y_pred = nb.predict(X_test_vec)\n",
    "        y_proba = nb.predict_proba(X_test_vec)\n",
    "\n",
    "        id_tokens['predictions'] = y_pred\n",
    "        id_tokens['probabilities'] = y_proba[:,1]\n",
    "\n",
    "        logo_list.append(id_tokens)\n",
    "        item_count += 1\n",
    "        print(f'text id: {id}, loop: {item_count}')\n",
    "\n",
    "    logo_df = pd.concat(logo_list)\n",
    "\n",
    "    return logo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text id: 52705351, loop: 1\n",
      "text id: 30672131, loop: 2\n",
      "text id: 40263168, loop: 3\n",
      "text id: 33964492, loop: 4\n",
      "text id: 35534191, loop: 5\n",
      "text id: 37522585, loop: 6\n",
      "text id: 34200601, loop: 7\n",
      "text id: 30497346, loop: 8\n",
      "text id: 33704434, loop: 9\n",
      "text id: 34889029, loop: 10\n",
      "text id: 27536020, loop: 11\n",
      "text id: 9401669, loop: 12\n",
      "text id: 25053859, loop: 13\n",
      "text id: 20325682, loop: 14\n",
      "text id: 16334435, loop: 15\n",
      "text id: 27446335, loop: 16\n",
      "text id: 28268808, loop: 17\n",
      "text id: 9680840, loop: 18\n",
      "text id: 24216613, loop: 19\n",
      "text id: 4102567, loop: 20\n",
      "text id: 5762899, loop: 21\n",
      "text id: 25706614, loop: 22\n",
      "text id: 24009643, loop: 23\n",
      "text id: 23907943, loop: 24\n",
      "text id: 22911136, loop: 25\n",
      "text id: 23294782, loop: 26\n",
      "text id: 21285821, loop: 27\n",
      "text id: 9832895, loop: 28\n",
      "text id: 20520542, loop: 29\n",
      "text id: 13708740, loop: 30\n",
      "text id: 11344053, loop: 31\n",
      "text id: 10896180, loop: 32\n",
      "text id: 7013194, loop: 33\n",
      "text id: 6770071, loop: 34\n",
      "text id: 1805647, loop: 35\n",
      "text id: 444476, loop: 36\n",
      "text id: 207589, loop: 37\n",
      "text id: 206617, loop: 38\n",
      "text id: 206569, loop: 39\n",
      "text id: 417, loop: 40\n",
      "text id: 105, loop: 41\n",
      "text id: 121, loop: 42\n",
      "text id: 141, loop: 43\n",
      "text id: 158, loop: 44\n",
      "text id: 21839, loop: 45\n",
      "text id: 42671, loop: 46\n"
     ]
    }
   ],
   "source": [
    "logo_mnb_c_pro = mnb_model(processed, 'processed_text', 'is_Austen_bool', CountVectorizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo_mnb_c_pro.to_csv('../data/logo_mnb_c_pro.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10340   662]\n",
      " [  410  1730]]\n",
      "0.9184294627910516\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95     11002\n",
      "           1       0.72      0.81      0.76      2140\n",
      "\n",
      "    accuracy                           0.92     13142\n",
      "   macro avg       0.84      0.87      0.86     13142\n",
      "weighted avg       0.92      0.92      0.92     13142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_matrix, acc_score, class_report = h.get_metrics(logo_mnb_c_pro, 'is_Austen_bool', 'predictions')\n",
    "\n",
    "print(conf_matrix)\n",
    "print(acc_score)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text id: 52705351, loop: 1\n",
      "text id: 30672131, loop: 2\n",
      "text id: 40263168, loop: 3\n",
      "text id: 33964492, loop: 4\n",
      "text id: 35534191, loop: 5\n",
      "text id: 37522585, loop: 6\n",
      "text id: 34200601, loop: 7\n",
      "text id: 30497346, loop: 8\n",
      "text id: 33704434, loop: 9\n",
      "text id: 34889029, loop: 10\n",
      "text id: 27536020, loop: 11\n",
      "text id: 9401669, loop: 12\n",
      "text id: 25053859, loop: 13\n",
      "text id: 20325682, loop: 14\n",
      "text id: 16334435, loop: 15\n",
      "text id: 27446335, loop: 16\n",
      "text id: 28268808, loop: 17\n",
      "text id: 9680840, loop: 18\n",
      "text id: 24216613, loop: 19\n",
      "text id: 4102567, loop: 20\n",
      "text id: 5762899, loop: 21\n",
      "text id: 25706614, loop: 22\n",
      "text id: 24009643, loop: 23\n",
      "text id: 23907943, loop: 24\n",
      "text id: 22911136, loop: 25\n",
      "text id: 23294782, loop: 26\n",
      "text id: 21285821, loop: 27\n",
      "text id: 9832895, loop: 28\n",
      "text id: 20520542, loop: 29\n",
      "text id: 13708740, loop: 30\n",
      "text id: 11344053, loop: 31\n",
      "text id: 10896180, loop: 32\n",
      "text id: 7013194, loop: 33\n",
      "text id: 6770071, loop: 34\n",
      "text id: 1805647, loop: 35\n",
      "text id: 444476, loop: 36\n",
      "text id: 207589, loop: 37\n",
      "text id: 206617, loop: 38\n",
      "text id: 206569, loop: 39\n",
      "text id: 417, loop: 40\n",
      "text id: 105, loop: 41\n",
      "text id: 121, loop: 42\n",
      "text id: 141, loop: 43\n",
      "text id: 158, loop: 44\n",
      "text id: 21839, loop: 45\n",
      "text id: 42671, loop: 46\n"
     ]
    }
   ],
   "source": [
    "logo_mnb_tf_pro = mnb_model(processed, 'processed_text', 'is_Austen_bool', TfidfVectorizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logo_mnb_tf_pro.to_csv('../data/logo_mnb_tf_pro.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10978    24]\n",
      " [ 2138     2]]\n",
      "0.8354892710394156\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91     11002\n",
      "           1       0.08      0.00      0.00      2140\n",
      "\n",
      "    accuracy                           0.84     13142\n",
      "   macro avg       0.46      0.50      0.46     13142\n",
      "weighted avg       0.71      0.84      0.76     13142\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_matrix, acc_score, class_report = h.get_metrics(logo_mnb_tf_pro, 'is_Austen_bool', 'predictions')\n",
    "\n",
    "print(conf_matrix)\n",
    "print(acc_score)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
